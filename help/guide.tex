\documentclass[english]{article}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{hyperref}

\usepackage{parskip}
%\usepackage{babel}
\begin{document}

\title{Apache Spark Quick Guide \\
Python}


\author{Joshua Jansen Van Vueren}

\maketitle

\section*{Introduction}
This document seeks to outline and describe the model utilised by Apache Spark.
\\\\
"Apache Spark is a fast and general-purpose cluster computing system."

\section{Terminology}
\begin{itemize}
\item \textbf{Resilient Distributed Datasets - RDD: } fault-tolerant collection of elements that can be operated on in parallel. (Old Programming Interface - pre Spark 2.0)
\item \textbf{Dataset: } New programming interface, better performance over RDD's.
\item \textbf{Parallelization: } members from collection are copied to form a distributed dataset, to be operated on in parallel. Slicing the data into a number of partitions to be used in the cluster.
\item \textbf{Cluster: } ...
\item \textbf{Cloud Dataproc: } Google Cloud Dataproc lets you provision Apache Hadoop clusters and connect to underlying analytic data stores.
\end{itemize}

\section{Other Documentation and Links}
\begin{itemize}
\item \href{https://cloud.google.com/dataproc/docs/tutorials/gcs-connector-spark-tutorial}{Google Cloud Storage Connector with Apache Spark}
\end{itemize}

\end{document}